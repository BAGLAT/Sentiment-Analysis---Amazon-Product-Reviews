{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from contractions import contractions_dict\n",
    "from string import punctuation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Amazon Customer Reviews DataFrame from JSON objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('Cell_Phones_and_Accessories_5.json.gz')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['reviewText','summary'])\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0    706102\n",
      "4.0    184293\n",
      "3.0    98189 \n",
      "1.0    81469 \n",
      "2.0    57153 \n",
      "Name: overall, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.0    62.641789\n",
       "4.0    16.349540\n",
       "3.0    8.710830 \n",
       "1.0    7.227517 \n",
       "2.0    5.070324 \n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['overall'].value_counts())\n",
    "df['overall'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate positive and negative reviews for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_negative_reviews = df[df['overall']<3].iloc[:100000]\n",
    "df_positive_reviews = df[df['overall']>3].iloc[:200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.iloc[:100]\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Text PreProcssing Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text, contractions_dict):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())),\n",
    "                                      flags=re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contractions_dict.get(match) \\\n",
    "            if contractions_dict.get(match) \\\n",
    "            else contractions_dict.get(match.lower())\n",
    "        expanded_contraction = expanded_contraction\n",
    "        return expanded_contraction\n",
    "\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "\n",
    "\n",
    "def strip_punctuation(s):\n",
    "    return ''.join(c for c in s if c not in punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "def cleanme(txt):\n",
    "    sent = txt.lower()\n",
    "    sent_expanded_contractions = expand_contractions(sent,contractions_dict)\n",
    "    sent_expanded_contractions = re.sub(r'(?<=[.,])(?=[^\\s])', r' ', sent_expanded_contractions)\n",
    "    sent_without_punct = strip_punctuation(sent_expanded_contractions)\n",
    "    sent_without_digits=re.sub('[0-9]+', '', sent_without_punct)\n",
    "    \n",
    "    TOKENIZER = RegexpTokenizer('(?u)\\W+|\\$[\\d\\.]+|\\S+')\n",
    "#     wrds = TOKENIZER.tokenize(sent_without_punct)\n",
    "    wrds = word_tokenize(sent_without_digits)\n",
    "    to_remove = ['no', 'not']\n",
    "    new_stopwords = set(stopwords.words('english')).difference(to_remove)\n",
    "    clwrds = [w for w in wrds if not w in new_stopwords]\n",
    "    ln = len(clwrds)\n",
    "    if ln>0:\n",
    "        pos = pd.DataFrame(pos_tag(wrds))\n",
    "        pos = (\" \".join(list(pos[pos[1].str.contains(\"JJ\")].iloc[:,0]))).split(\" \")\n",
    "        l2 = [\"i\",\"you\",\"me\"]\n",
    "        pos = [x for x in pos if x not in l2]\n",
    "    else:\n",
    "        pos = [\"\"]\n",
    "    rt = [ln, \" \".join(clwrds), \" \".join(pos)]\n",
    "    return(rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Negative Reviews WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp = list()\n",
    "for i in range(100000):\n",
    "    tmp.append(cleanme(df_negative_reviews.iloc[i,:]['reviewText']))\n",
    "tmp = pd.DataFrame(tmp)\n",
    "tmp.columns = ['reviewlen', 'cleanrev', 'adjreview']\n",
    "\n",
    "(tmp.head())\n",
    "\n",
    "\n",
    "df_negative_reviews_new = df_negative_reviews.reset_index()\n",
    "# df_negative_reviews_new.drop(['reviewlen', 'cleanrev', 'adjreview'], axis=1, inplace=True)\n",
    "df_negative_reviews_new = pd.concat([df_negative_reviews_new,tmp], axis=1)\n",
    "df_negative_reviews_new = df_negative_reviews_new[['overall','reviewText','summary','reviewlen', 'cleanrev', 'adjreview']]\n",
    "df_negative_reviews_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "\n",
    "txt = df_negative_reviews_new.cleanrev.str.lower().str.replace(r'\\|', ' ').str.cat(sep=' ')\n",
    "words = nltk.tokenize.word_tokenize(txt)\n",
    "lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in words]\n",
    "# stemmed_word = [snowball_stemmer.stem(word) for word in words]\n",
    "bgs = nltk.trigrams(lemmatized_word)\n",
    "\n",
    "#compute frequency distribution for all the bigrams in the text\n",
    "fdist = nltk.FreqDist(bgs)\n",
    "fdist.most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for key, value in fdist.items() :\n",
    "#     print (\"_\".join(key), value)\n",
    "    d[\"_\".join(key)] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "WC_height = 200\n",
    "WC_width = 400\n",
    "WC_max_words = 50\n",
    "wordcloud = WordCloud(max_words=WC_max_words, height=WC_height, width=WC_width, background_color=\"white\")\n",
    "wordcloud.generate_from_frequencies(frequencies=d)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "wordcloud.to_file(\"WordCloud_Bigrams_frequent_words.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Positive Reviews WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = list()\n",
    "for i in range(150000):\n",
    "    tmp.append(cleanme(df_positive_reviews.iloc[i,:]['reviewText']))\n",
    "tmp = pd.DataFrame(tmp)\n",
    "tmp.columns = ['reviewlen', 'cleanrev', 'adjreview']\n",
    "\n",
    "(tmp.head())\n",
    "\n",
    "\n",
    "df_positive_reviews_new = df_positive_reviews.reset_index()\n",
    "df_positive_reviews_new = pd.concat([df_positive_reviews_new,tmp], axis=1)\n",
    "df_positive_reviews_new = df_positive_reviews_new[['overall','reviewText','summary','reviewlen', 'cleanrev', 'adjreview']]\n",
    "df_positive_reviews_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "\n",
    "txt = df_positive_reviews_new.cleanrev.str.lower().str.replace(r'\\|', ' ').str.cat(sep=' ')\n",
    "words = nltk.tokenize.word_tokenize(txt)\n",
    "lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in words]\n",
    "# stemmed_word = [snowball_stemmer.stem(word) for word in words]\n",
    "\n",
    "bgs = nltk.trigrams(lemmatized_word)\n",
    "\n",
    "#compute frequency distribution for all the bigrams in the text\n",
    "fdist = nltk.FreqDist(bgs)\n",
    "fdist.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for key, value in fdist.items() :\n",
    "#     print (\"_\".join(key), value)\n",
    "    d[\"_\".join(key)] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "WC_height = 200\n",
    "WC_width = 400\n",
    "WC_max_words = 50\n",
    "wordcloud = WordCloud(max_words=WC_max_words, height=WC_height, width=WC_width, background_color=\"white\")\n",
    "wordcloud.generate_from_frequencies(frequencies=d)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "wordcloud.to_file(\"WordCloud_Positive_Reviews.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcess 200K reviews to be used to build classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewlen</th>\n",
       "      <th>cleanrev</th>\n",
       "      <th>adjreview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Looks even better in person. Be careful to not drop your phone so often because the rhinestones will fall off (duh). More of a decorative case than it is protective, but I will say that it fits perfectly and securely on my phone. Overall, very pleased with this purchase.</td>\n",
       "      <td>Can't stop won't stop looking at it</td>\n",
       "      <td>23</td>\n",
       "      <td>looks even better person careful not drop phone often rhinestones fall duh decorative case protective say fits perfectly securely phone overall pleased purchase</td>\n",
       "      <td>careful more decorative protective overall pleased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>When you don't want to spend a whole lot of cash but want a great deal...this is the shop to buy from!</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>not want spend whole lot cash want great deal shop buy</td>\n",
       "      <td>whole great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>so the case came on time, i love the design. I'm actually missing 2 studs but nothing too noticeable the studding is almost a bit sloppy around the bow, but once again not too noticeable. I haven't put in my phone yet so this is just what I've notice so far</td>\n",
       "      <td>Its okay</td>\n",
       "      <td>24</td>\n",
       "      <td>case came time love design actually missing studs nothing noticeable studding almost bit sloppy around bow not noticeable not put phone yet notice far</td>\n",
       "      <td>noticeable sloppy noticeable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY WERE OKAY WITH IT.  JUST NOT WHAT I EXPECTED.</td>\n",
       "      <td>CASE</td>\n",
       "      <td>7</td>\n",
       "      <td>not care gave gift okay not expected</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I liked it because it was cute, but the studs fall off easily and to protect a phone this would not be recommended. Buy if you just like it for looks.</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>13</td>\n",
       "      <td>liked cute studs fall easily protect phone would not recommended buy like looks</td>\n",
       "      <td>cute studs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  \\\n",
       "0  5.0       \n",
       "1  5.0       \n",
       "2  3.0       \n",
       "3  2.0       \n",
       "4  4.0       \n",
       "\n",
       "                                                                                                                                                                                                                                                                        reviewText  \\\n",
       "0  Looks even better in person. Be careful to not drop your phone so often because the rhinestones will fall off (duh). More of a decorative case than it is protective, but I will say that it fits perfectly and securely on my phone. Overall, very pleased with this purchase.   \n",
       "1  When you don't want to spend a whole lot of cash but want a great deal...this is the shop to buy from!                                                                                                                                                                            \n",
       "2  so the case came on time, i love the design. I'm actually missing 2 studs but nothing too noticeable the studding is almost a bit sloppy around the bow, but once again not too noticeable. I haven't put in my phone yet so this is just what I've notice so far                 \n",
       "3  DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY WERE OKAY WITH IT.  JUST NOT WHAT I EXPECTED.                                                                                                                                                                                      \n",
       "4  I liked it because it was cute, but the studs fall off easily and to protect a phone this would not be recommended. Buy if you just like it for looks.                                                                                                                            \n",
       "\n",
       "                               summary  reviewlen  \\\n",
       "0  Can't stop won't stop looking at it  23          \n",
       "1  1                                    11          \n",
       "2  Its okay                             24          \n",
       "3  CASE                                 7           \n",
       "4  Cute!                                13          \n",
       "\n",
       "                                                                                                                                                           cleanrev  \\\n",
       "0  looks even better person careful not drop phone often rhinestones fall duh decorative case protective say fits perfectly securely phone overall pleased purchase   \n",
       "1  not want spend whole lot cash want great deal shop buy                                                                                                             \n",
       "2  case came time love design actually missing studs nothing noticeable studding almost bit sloppy around bow not noticeable not put phone yet notice far             \n",
       "3  not care gave gift okay not expected                                                                                                                               \n",
       "4  liked cute studs fall easily protect phone would not recommended buy like looks                                                                                    \n",
       "\n",
       "                                            adjreview  \n",
       "0  careful more decorative protective overall pleased  \n",
       "1  whole great                                         \n",
       "2  noticeable sloppy noticeable                        \n",
       "3                                                      \n",
       "4  cute studs                                          "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df.iloc[:200000]\n",
    "\n",
    "tmp = list()\n",
    "for i in range(200000):\n",
    "    tmp.append(cleanme(df_new.iloc[i,:]['reviewText']))\n",
    "tmp = pd.DataFrame(tmp)\n",
    "tmp.columns = ['reviewlen', 'cleanrev', 'adjreview']\n",
    "\n",
    "(tmp.head())\n",
    "\n",
    "\n",
    "df_new = df_new.reset_index()\n",
    "# df_negative_reviews_new.drop(['reviewlen', 'cleanrev', 'adjreview'], axis=1, inplace=True)\n",
    "df_new = pd.concat([df_new,tmp], axis=1)\n",
    "df_new = df_new[['overall','reviewText','summary','reviewlen', 'cleanrev', 'adjreview']]\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>cleanReviewLength</th>\n",
       "      <th>cleanReview</th>\n",
       "      <th>adjectives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Looks even better in person. Be careful to not drop your phone so often because the rhinestones will fall off (duh). More of a decorative case than it is protective, but I will say that it fits perfectly and securely on my phone. Overall, very pleased with this purchase.</td>\n",
       "      <td>Can't stop won't stop looking at it</td>\n",
       "      <td>23</td>\n",
       "      <td>looks even better person careful not drop phone often rhinestones fall duh decorative case protective say fits perfectly securely phone overall pleased purchase</td>\n",
       "      <td>careful more decorative protective overall pleased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>When you don't want to spend a whole lot of cash but want a great deal...this is the shop to buy from!</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>not want spend whole lot cash want great deal shop buy</td>\n",
       "      <td>whole great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>so the case came on time, i love the design. I'm actually missing 2 studs but nothing too noticeable the studding is almost a bit sloppy around the bow, but once again not too noticeable. I haven't put in my phone yet so this is just what I've notice so far</td>\n",
       "      <td>Its okay</td>\n",
       "      <td>24</td>\n",
       "      <td>case came time love design actually missing studs nothing noticeable studding almost bit sloppy around bow not noticeable not put phone yet notice far</td>\n",
       "      <td>noticeable sloppy noticeable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY WERE OKAY WITH IT.  JUST NOT WHAT I EXPECTED.</td>\n",
       "      <td>CASE</td>\n",
       "      <td>7</td>\n",
       "      <td>not care gave gift okay not expected</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I liked it because it was cute, but the studs fall off easily and to protect a phone this would not be recommended. Buy if you just like it for looks.</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>13</td>\n",
       "      <td>liked cute studs fall easily protect phone would not recommended buy like looks</td>\n",
       "      <td>cute studs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  \\\n",
       "0  5.0       \n",
       "1  5.0       \n",
       "2  3.0       \n",
       "3  2.0       \n",
       "4  4.0       \n",
       "\n",
       "                                                                                                                                                                                                                                                                        reviewText  \\\n",
       "0  Looks even better in person. Be careful to not drop your phone so often because the rhinestones will fall off (duh). More of a decorative case than it is protective, but I will say that it fits perfectly and securely on my phone. Overall, very pleased with this purchase.   \n",
       "1  When you don't want to spend a whole lot of cash but want a great deal...this is the shop to buy from!                                                                                                                                                                            \n",
       "2  so the case came on time, i love the design. I'm actually missing 2 studs but nothing too noticeable the studding is almost a bit sloppy around the bow, but once again not too noticeable. I haven't put in my phone yet so this is just what I've notice so far                 \n",
       "3  DON'T CARE FOR IT.  GAVE IT AS A GIFT AND THEY WERE OKAY WITH IT.  JUST NOT WHAT I EXPECTED.                                                                                                                                                                                      \n",
       "4  I liked it because it was cute, but the studs fall off easily and to protect a phone this would not be recommended. Buy if you just like it for looks.                                                                                                                            \n",
       "\n",
       "                               summary  cleanReviewLength  \\\n",
       "0  Can't stop won't stop looking at it  23                  \n",
       "1  1                                    11                  \n",
       "2  Its okay                             24                  \n",
       "3  CASE                                 7                   \n",
       "4  Cute!                                13                  \n",
       "\n",
       "                                                                                                                                                        cleanReview  \\\n",
       "0  looks even better person careful not drop phone often rhinestones fall duh decorative case protective say fits perfectly securely phone overall pleased purchase   \n",
       "1  not want spend whole lot cash want great deal shop buy                                                                                                             \n",
       "2  case came time love design actually missing studs nothing noticeable studding almost bit sloppy around bow not noticeable not put phone yet notice far             \n",
       "3  not care gave gift okay not expected                                                                                                                               \n",
       "4  liked cute studs fall easily protect phone would not recommended buy like looks                                                                                    \n",
       "\n",
       "                                           adjectives  \n",
       "0  careful more decorative protective overall pleased  \n",
       "1  whole great                                         \n",
       "2  noticeable sloppy noticeable                        \n",
       "3                                                      \n",
       "4  cute studs                                          "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns = ['overall','reviewText','summary','cleanReviewLength', 'cleanReview', 'adjectives']\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Polarity of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob, Word\n",
    "def detect_polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "df_new['polarity'] = df_new.reviewText.apply(detect_polarity)\n",
    "df_new[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Multi-Class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=False, max_features = 10000, min_df=5,max_df=0.30,ngram_range= (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 6), (10000, 6))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "review_df = pd.concat([df_new[df_new['overall']==1.0].sample(n=10000),df_new[df_new['overall']==2.0].sample(n=10000),\n",
    "                    df_new[df_new['overall']==3.0].sample(n=10000),df_new[df_new['overall']==4.0].sample(n=10000),\n",
    "                    df_new[df_new['overall']==5.0].sample(n=10000)])\n",
    "review_df = review_df[['cleanReview','overall']]\n",
    "train, test = train_test_split(review_df, test_size=0.2)\n",
    "\n",
    "train['overall'].hist();\n",
    "test['overall'].hist();\n",
    "\n",
    "train = pd.get_dummies(train, columns = ['overall'])\n",
    "train.head()\n",
    "\n",
    "test = pd.get_dummies(test, columns = ['overall'])\n",
    "test.head()\n",
    "\n",
    "train.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBFeatures(BaseEstimator):\n",
    "    '''Class implementation of Jeremy Howards NB Linear model'''\n",
    "    def __init__(self, alpha):\n",
    "        # Smoothing Parameter: always going to be one for my use\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def preprocess_x(self, x, r):\n",
    "        return x.multiply(r)\n",
    "    \n",
    "    # calculate probabilities\n",
    "    def pr(self, x, y_i, y):\n",
    "        p = x[y == y_i].sum(0)\n",
    "        return (p + self.alpha)/((y==y_i).sum()+self.alpha)\n",
    "    \n",
    "    # calculate the log ratio and represent as sparse matrix\n",
    "    # ie fit the nb model\n",
    "    def fit(self, x, y = None):\n",
    "        self._r = sparse.csr_matrix(np.log(self.pr(x, 1, y) /self.pr(x, 0, y)))\n",
    "        return self\n",
    "    \n",
    "    # apply the nb fit to original features x\n",
    "    def transform(self, x):\n",
    "        x_nb = self.preprocess_x(x, self._r)\n",
    "        return x_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline using sklearn pipeline:\n",
    "    # I basically create my tfidf features which are fed to my NB model \n",
    "    # for probability calculations. Then those are fed as input to my \n",
    "    # logistic regression model.\n",
    "lr = LogisticRegression()\n",
    "nb = NBFeatures(1)\n",
    "p = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('nb', nb),\n",
    "    ('lr', lr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score for class overall_1.0 is 0.8514749991893641\n",
      "CV score for class overall_2.0 is 0.7940000678658036\n",
      "CV score for class overall_3.0 is 0.7977499722478812\n",
      "CV score for class overall_4.0 is 0.8018499997523186\n",
      "CV score for class overall_5.0 is 0.8517000160642234\n"
     ]
    }
   ],
   "source": [
    "class_names = ['overall_1.0', 'overall_2.0','overall_3.0','overall_4.0','overall_5.0']\n",
    "scores = []\n",
    "preds = np.zeros((len(test), len(class_names)))\n",
    "for i, class_name in enumerate(class_names):\n",
    "    train_target = train[class_name]    \n",
    "    cv_score = np.mean(cross_val_score(estimator = p, X = train['cleanReview'].values, \n",
    "                                      y = train_target, cv = 3, scoring = 'accuracy'))\n",
    "    scores.append(cv_score)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "    p.fit(train['cleanReview'].values, train_target)\n",
    "    preds[:,i] = p.predict_proba(test['cleanReview'].values)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.64      0.60      2071\n",
      "           1       0.40      0.37      0.38      1995\n",
      "           2       0.38      0.34      0.36      1983\n",
      "           3       0.44      0.40      0.42      1980\n",
      "           4       0.57      0.67      0.62      1971\n",
      "\n",
      "    accuracy                           0.48     10000\n",
      "   macro avg       0.47      0.48      0.48     10000\n",
      "weighted avg       0.47      0.48      0.48     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = metrics.classification_report(np.argmax(test[class_names].values, axis = 1),np.argmax(preds, axis = 1))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Other Multi-Class Classifier Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_new=df_new.rename(columns = {'overall':'overall_rating'})\n",
    "df_new['overall_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.concat([df_new[df_new['overall_rating']==1.0].sample(n=3000),df_new[df_new['overall_rating']==2.0].sample(n=3000),\n",
    "                    df_new[df_new['overall_rating']==3.0].sample(n=3000),df_new[df_new['overall_rating']==4.0].sample(n=3000),\n",
    "                    df_new[df_new['overall_rating']==5.0].sample(n=3000)])\n",
    "df_res['overall_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_100 = df_res.copy()\n",
    "\n",
    "# v = TfidfVectorizer(max_features = 100000, min_df=10, max_df=0.60)\n",
    "v = TfidfVectorizer(max_features = 10000, min_df=5,max_df=0.60)\n",
    "x = v.fit_transform(df_100['cleanReview'])\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(x.toarray(), columns=v.get_feature_names())\n",
    "df_100 = df_100.drop('cleanReview', axis=1)\n",
    "\n",
    "df_100.reset_index(drop=True, inplace=True)\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "# print(df_100)\n",
    "res = pd.concat([df_100, df1], axis=1)\n",
    "res.head(-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = res[res.columns.difference(['reviewText','summary', 'adjectives', 'overall_rating'])]\n",
    "normalized_res1 = res1\n",
    "# normalized_res1=(res1-res1.min())/(res1.max()-res1.min())\n",
    "# print(normalized_res1.head(100))\n",
    "y = res['overall_rating'].values.reshape(-1,1)\n",
    "\n",
    "res1.shape, y.shape\n",
    "\n",
    "# y = res['rating']\n",
    "# len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_res1, y, test_size=0.2, random_state=101)\n",
    "lr = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg').fit(X_train,y_train)\n",
    "\n",
    "print (\"Multinomial Logistic regression Train Accuracy :: \", metrics.accuracy_score(y_train, lr.predict(X_train)))\n",
    "print (\"Multinomial Logistic regression Test Accuracy :: \", metrics.accuracy_score(y_test, lr.predict(X_test)))\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, lr.predict(X_test))\n",
    "\n",
    "\n",
    "class_names=[1,2,3,4,5] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "ax.xaxis.set_ticklabels(class_names)\n",
    "ax.yaxis.set_ticklabels(class_names)\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_res1, y, test_size=0.2)\n",
    "knn = KNeighborsClassifier(n_neighbors = 15).fit(X_train, y_train)\n",
    "\n",
    "accuracy = knn.score(X_test, y_test) \n",
    "print (accuracy)\n",
    "  \n",
    "# creating a confusion matrix \n",
    "knn_predictions = knn.predict(X_test)  \n",
    "cnf_matrix = metrics.confusion_matrix(y_test, knn_predictions) \n",
    "\n",
    "class_names=[1,2,3,4,5] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "ax.xaxis.set_ticklabels(class_names)\n",
    "ax.yaxis.set_ticklabels(class_names)\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "import seaborn as sns\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_res1, y, test_size=0.2, random_state=101)\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train,y_train)\n",
    "\n",
    "print (\"Multinomial Logistic regression Train Accuracy :: \", metrics.accuracy_score(y_train, svm.predict(X_train)))\n",
    "print (\"Multinomial Logistic regression Test Accuracy :: \", metrics.accuracy_score(y_test, svm.predict(X_test)))\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, svm.predict(X_test))\n",
    "cnf_matrix\n",
    "\n",
    "class_names=[1,2,3,4,5] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "ax.xaxis.set_ticklabels(class_names)\n",
    "ax.yaxis.set_ticklabels(class_names)\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_new['cleanReview'], df_new['overall_rating'], random_state = 101)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "print (\"Multinomial Logistic regression Train Accuracy :: \", metrics.accuracy_score(y_train, clf.predict(X_train_tfidf)))\n",
    "print (\"Multinomial Logistic regression Test Accuracy :: \", metrics.accuracy_score(y_test, clf.predict(count_vect.transform(X_test))))\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, clf.predict(count_vect.transform(X_test)))\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "class_names=[1,2,3,4,5] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "ax.xaxis.set_ticklabels(class_names)\n",
    "ax.yaxis.set_ticklabels(class_names)\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': lm.predict(X_test).flatten()})\n",
    "pred_df\n",
    "pred_df1 = pred_df.head(20)\n",
    "pred_df1.plot(kind='bar',figsize=(16,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
